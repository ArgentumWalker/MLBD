{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Student-Model\" data-toc-modified-id=\"Student-Model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Student Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-processing\" data-toc-modified-id=\"Data-processing-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Data processing</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-Model\" data-toc-modified-id=\"Define-Model-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Define Model</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Train</a></span></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#ROC-AUC\" data-toc-modified-id=\"ROC-AUC-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>ROC AUC</a></span></li><li><span><a href=\"#Compression-rate\" data-toc-modified-id=\"Compression-rate-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Compression rate</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Model\n",
    "\n",
    "\n",
    "Нужно обучть небольшую модель на [soft таргетах](https://drive.google.com/file/d/1tBbPOUT-Ow9f3zTDApykGXYwt-KslYle/view?usp=sharing)  модели учителя, которая не сильно уступала бы в качестве учителю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from deepctr.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr.models.dcn import DCN\n",
    "\n",
    "from collections import defaultdict\n",
    "from keras.callbacks.callbacks import *\n",
    "from keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './criteo'\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train.csv')\n",
    "RETAIN_PATH = 'soft_targets_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_target = pd.read_csv(RETAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.532062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.483268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.126496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>0.750299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>0.784883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>0.010671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>117</td>\n",
       "      <td>0.466868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>121</td>\n",
       "      <td>0.554683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>135</td>\n",
       "      <td>0.110773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>139</td>\n",
       "      <td>0.262256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id      prob\n",
       "0   12  0.532062\n",
       "1   26  0.483268\n",
       "2   39  0.126496\n",
       "3   41  0.750299\n",
       "4   85  0.784883\n",
       "5  108  0.010671\n",
       "6  117  0.466868\n",
       "7  121  0.554683\n",
       "8  135  0.110773\n",
       "9  139  0.262256"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_c0,_c1,_c2,_c3,_c4,_c5,_c6,_c7,_c8,_c9,_c10,_c11,_c12,_c13,_c14,_c15,_c16,_c17,_c18,_c19,_c20,_c21,_c22,_c23,_c24,_c25,_c26,_c27,_c28,_c29,_c30,_c31,_c32,_c33,_c34,_c35,_c36,_c37,_c38,_c39,id\n",
      "\n",
      "1,0,-1,\"\",\"\",1465,0,17,0,4,0,4,\"\",\"\",241546e0,38a947a1,fa673455,6a14f9b9,25c83c98,fe6b92e5,1c86e0eb,1f89b562,a73ee510,e7ba2569,755e4a50,208d9687,5978055e,07d13a8f,5182f694,f8b34416,e5ba7672,e5f8f18f,\"\",\"\",f3ddd519,\"\",32c7478e,b34f3128,\"\",\"\",12\n",
      "\n",
      "1,0,1,20,16,1548,93,42,32,912,0,15,1,16,8cf07265,942f9a8d,a8e40bcf,0365276a,25c83c98,7e0ccccf,3f4ec687,1f89b562,a73ee510,726f00fd,c4adf918,27c604a6,85dbe138,07d13a8f,a8e962af,c449f783,27c07bd6,1f868fdd,21ddcdc9,a458ea53,7eee76d1,\"\",32c7478e,9af06ad9,9d93af03,cdfe5ab7,26\n",
      "\n",
      "0,8,0,15,20,115,24,8,23,24,2,2,\"\",20,5a9ed9b0,c66fca21,78171040,373c404a,25c83c98,\"\",8ff6f5af,0b153874,a73ee510,5ba575e7,b5a9f90e,6766a7f0,949ea585,1adce6ef,8736735c,59974c9c,8efede7f,1304f63b,21ddcdc9,b1252a9d,07b2853e,\"\",32c7478e,94bde4f2,010f6491,09b76f8d,39\n",
      "\n",
      "1,88,319,\"\",4,5,4,89,40,88,3,4,12,4,05db9164,08d6d899,333440d5,fc86bde0,25c83c98,fbad5c96,f00bddf8,0b153874,a73ee510,83ff688a,55795b33,1b0c8aa3,39795005,b28479f6,bffbd637,4a838997,8efede7f,bbf70d82,\"\",\"\",16e2e3b3,\"\",32c7478e,d859b4dd,\"\",\"\",41\n",
      "\n",
      "0,0,53,\"\",10,6550,98,34,11,349,0,9,\"\",10,05db9164,207b2d81,8bd78c57,394ee067,25c83c98,6f6d9be8,283d5555,0b153874,a73ee510,3b08e48b,3d5fb018,e5f6b330,94172618,07d13a8f,0bf0feff,402a9036,e5ba7672,fa0643ee,21ddcdc9,b1252a9d,0094bc78,\"\",32c7478e,29ece3ed,001f3601,402185f3,85\n",
      "\n",
      "0,\"\",5,30,4,\"\",\"\",0,5,4,\"\",0,\"\",5,68fd1e64,207b2d81,74e1a23a,9a6888fb,25c83c98,7e0ccccf,d356c7e6,5b392875,7cc72ec2,3b08e48b,727af3e2,fb8fab62,49fe3d4e,b28479f6,231f3923,c6b1e1b2,2005abd1,25935396,21ddcdc9,5840adea,99c09e97,\"\",be7c41b4,335a6a1e,001f3601,8d8eb391,108\n",
      "\n",
      "1,\"\",-1,\"\",\"\",446,30,2,27,28,\"\",1,\"\",\"\",05db9164,38d50e09,c86b2d8d,657dc3b9,25c83c98,6f6d9be8,fe4dce68,0b153874,a73ee510,16a81a6c,68357db6,1ca7a526,768f6658,07d13a8f,e2275836,ba46c3a1,07c540c4,fffe2a63,21ddcdc9,b1252a9d,eb0fc6f8,\"\",32c7478e,df487a73,001f3601,c27f155b,117\n",
      "\n",
      "1,1,0,31,9,226,22,32,13,177,1,7,0,11,5a9ed9b0,942f9a8d,013bceb0,136ff514,25c83c98,6f6d9be8,3f4ec687,7b6fecd5,a73ee510,726f00fd,c4adf918,65b6ef3b,85dbe138,1adce6ef,ae97ecc3,a55f20ce,3486227d,1f868fdd,cd11c728,a458ea53,00680113,\"\",32c7478e,ad4c56a0,e8b83407,8270b5de,121\n",
      "\n",
      "0,\"\",0,17,3,19811,\"\",0,3,54,\"\",0,\"\",3,05db9164,f0cf0024,6f67f7e5,41274cd7,25c83c98,fbad5c96,9b6a4cc9,0b153874,a73ee510,a5aa06c8,8e3de34d,623049e6,b50e2ed0,b28479f6,e6c5b5cd,c92f3b61,1e88c74f,b04e4670,21ddcdc9,5840adea,60f6221e,\"\",32c7478e,43f13e8b,ea9a246c,731c3655,135\n",
      "\n",
      "3664931\n"
     ]
    }
   ],
   "source": [
    "max_k = 0\n",
    "with open(TRAIN_PATH) as f:\n",
    "    for k, line in enumerate(f):\n",
    "        if k < 10:\n",
    "            print(line)\n",
    "        max_k = k\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "Данные на Train/Validation/Test нужно разбить как 80/10/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_features_indices = [i for i in range(1, 14)]\n",
    "sparse_features_indices = [i for i in range(14, 40)]\n",
    "\n",
    "dense_features = ['c{}'.format(i) for i in dense_features_indices]\n",
    "sparse_features = ['c{}'.format(i) for i in sparse_features_indices]\n",
    "\n",
    "len(dense_features_indices), len(sparse_features_indices)\n",
    "\n",
    "min_arr = [0] * 40\n",
    "max_arr = [0] * 40\n",
    "range_arr = [0] * 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_minmax(filename, retain):\n",
    "    with open(filename) as f:\n",
    "        for k, line in enumerate(f):\n",
    "            if k == 0:\n",
    "                continue\n",
    "            features = line.split('\\n')[0].split(',')\n",
    "            if int(features[-1]) not in retain:\n",
    "                continue\n",
    "            for i, f_name in zip(dense_features_indices, dense_features):\n",
    "                val = features[i] if features[i] != '\"\"' else 0\n",
    "                val = float(val)\n",
    "                min_arr[i] = min(min_arr[i], val)\n",
    "                max_arr[i] = max(max_arr[i], val)\n",
    "                range_arr[i] = max_arr[i] - min_arr[i]\n",
    "\n",
    "\n",
    "def prepare_data_dict(batch):\n",
    "    data_dict = {}\n",
    "    for f_name in dense_features:\n",
    "        data_dict[f_name] = pd.core.series.Series(batch[f_name])\n",
    "\n",
    "    for f_name in sparse_features:\n",
    "        data_dict[f_name] = pd.core.series.Series(batch[f_name])\n",
    "\n",
    "    return data_dict\n",
    "                \n",
    "\n",
    "def generate_data(filename, retain, targets, batch_size=128):\n",
    "    data_teacher = defaultdict(list)\n",
    "    target = defaultdict(list)\n",
    "    labels = []\n",
    "    m = 0\n",
    "    \n",
    "    while True:\n",
    "        with open(filename) as f:\n",
    "            for k, line in enumerate(f):\n",
    "                if k == 0:\n",
    "                    continue\n",
    "                features = line.split('\\n')[0].split(',')\n",
    "                if int(features[-1]) not in retain:\n",
    "                    continue\n",
    "\n",
    "                labels.append(np.int32(features[0]))\n",
    "                target[\"target\"].append(np.float32(targets[m % len(targets)]))\n",
    "\n",
    "                for i, f_name in zip(dense_features_indices, dense_features):\n",
    "                    val = features[i] if features[i] != '\"\"' else 0\n",
    "                    val = (np.float32(val) - min_arr[i]) / range_arr[i] \n",
    "                    data_teacher[f_name].append(val)\n",
    "\n",
    "                for i, f_name in zip(sparse_features_indices, sparse_features):\n",
    "                    val = features[i] if features[i] != '\"\"' else '-1'\n",
    "                    data_teacher[f_name].append(val)\n",
    "\n",
    "                m += 1\n",
    "\n",
    "                if m % batch_size == 0:            \n",
    "                    data_dict = prepare_data_dict(data_teacher)\n",
    "                    yield data_dict, pd.core.series.Series(target[\"target\"])\n",
    "\n",
    "                    data_teacher = defaultdict(list)\n",
    "                    target = defaultdict(list)\n",
    "                    labels = []\n",
    "    \n",
    "    \n",
    "def get_data(filename, retain, targets):\n",
    "    data_teacher = defaultdict(list)\n",
    "    target = []\n",
    "    labels = []\n",
    "    \n",
    "    m = 0\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        for k, line in enumerate(f):\n",
    "            if k == 0:\n",
    "                continue\n",
    "            features = line.split('\\n')[0].split(',')\n",
    "            if int(features[-1]) not in retain:\n",
    "                continue\n",
    "\n",
    "            labels.append(np.int32(features[0]))\n",
    "            target.append(np.float32(targets[m]))\n",
    "\n",
    "            for i, f_name in zip(dense_features_indices, dense_features):\n",
    "                val = features[i] if features[i] != '\"\"' else 0\n",
    "                val = (float(val) - min_arr[i]) / range_arr[i] \n",
    "                data_teacher[f_name].append(val)\n",
    "\n",
    "            for i, f_name in zip(sparse_features_indices, sparse_features):\n",
    "                val = features[i] if features[i] != '\"\"' else '-1'\n",
    "                data_teacher[f_name].append(val)\n",
    "            \n",
    "            m += 1\n",
    "    data_dict = prepare_data_dict(data_teacher)\n",
    "    return labels, np.array(target), data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(soft_target, shuffle=False, test_size=0.2)\n",
    "test, validate = train_test_split(test, shuffle=False, test_size=0.5)\n",
    "\n",
    "all_retain = set(soft_target['id'].to_list())\n",
    "train_retain, train_target = set(train['id'].to_list()), train['prob'].to_numpy()\n",
    "test_retain, test_target = set(test['id'].to_list()), test['prob'].to_numpy()\n",
    "validate_retain, validate_target = set(validate['id'].to_list()), validate['prob'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_minmax(TRAIN_PATH, all_retain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_labels, validate_target, validate_data = get_data(TRAIN_PATH, validate_retain, validate_target)\n",
    "test_labels, test_target, test_data = get_data(TRAIN_PATH, test_retain, test_target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Можно также использовать Pruning и/или Quantinization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features_dims = dict([\n",
    "    ('c14', 1445),\n",
    "    ('c15', 556),\n",
    "    ('c16', 1130758),\n",
    "    ('c17', 360209),\n",
    "    ('c18', 304),\n",
    "    ('c19', 21),\n",
    "    ('c20', 11845),\n",
    "    ('c21', 631),\n",
    "    ('c22', 3),\n",
    "    ('c23', 49223),\n",
    "    ('c24', 5194),\n",
    "    ('c25', 985420),\n",
    "    ('c26', 3157),\n",
    "    ('c27', 26),\n",
    "    ('c28', 11588),\n",
    "    ('c29', 715441),\n",
    "    ('c30', 10),\n",
    "    ('c31', 4681),\n",
    "    ('c32', 2029),\n",
    "    ('c33', 4),\n",
    "    ('c34', 870796),\n",
    "    ('c35', 17),\n",
    "    ('c36', 15),\n",
    "    ('c37', 87605),\n",
    "    ('c38', 84),\n",
    "    ('c39', 58187)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_stat(max_vocab_size=20000, max_embedding_dim=75, hidden_size=(128, 128)):\n",
    "    fixlen_feature_columns = [SparseFeat(feat, \n",
    "                                         vocabulary_size=min(vocab_size, max_vocab_size), \n",
    "                                         embedding_dim=min(int(6 * (vocab_size) ** (0.25)), max_embedding_dim), \n",
    "                                         use_hash=True, dtype='string')\n",
    "                              for feat, vocab_size in sparse_features_dims.items()] + \\\n",
    "                            [DenseFeat(feat, 1,) for feat in dense_features]\n",
    "\n",
    "\n",
    "    linear_feature_columns = fixlen_feature_columns\n",
    "    dnn_feature_columns = fixlen_feature_columns\n",
    "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns, )\n",
    "    \n",
    "    model = DCN(linear_feature_columns, dnn_feature_columns, cross_num=2,\n",
    "            dnn_hidden_units=hidden_size, l2_reg_linear=0, l2_reg_embedding=0,\n",
    "            l2_reg_cross=0, l2_reg_dnn=0, init_std=0.0001, seed=1024, \n",
    "            dnn_use_bn=True, dnn_activation='relu', task='binary')\n",
    "\n",
    "    model.compile(\"adam\", 'mean_squared_error',\n",
    "                  metrics=['mean_squared_error'], )\n",
    "    \n",
    "    BATCH_SIZE = 3000\n",
    "    EPOCHS = 6\n",
    "    \n",
    "    #model.fit(test_data, test_target)\n",
    "    \n",
    "    model.fit(generate_data(TRAIN_PATH, train_retain, train_target, BATCH_SIZE),\n",
    "              use_multiprocessing=True, steps_per_epoch=3*len(train_retain)//(BATCH_SIZE * EPOCHS), \n",
    "              epochs=6, verbose=1)\n",
    "    model.save_weights('./tmp.h5')\n",
    "    \n",
    "    compression_rate = os.path.getsize('tmp.h5')/(1024 * 1024 * 168)\n",
    "    \n",
    "    pred_proba = model.predict(validate_data)\n",
    "    validation_rocauc = roc_auc_score(validate_labels, pred_proba)\n",
    "    pred_proba = model.predict(test_data)\n",
    "    test_rocauc = roc_auc_score(test_labels, pred_proba)\n",
    "    \n",
    "    clear_session()\n",
    "    \n",
    "    return compression_rate, validation_rocauc, test_rocauc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "Train for 488 steps\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "488/488 [==============================] - 172s 352ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 2/6\n",
      "488/488 [==============================] - 169s 346ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 3/6\n",
      "488/488 [==============================] - 171s 351ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 4/6\n",
      "488/488 [==============================] - 170s 348ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 5/6\n",
      "488/488 [==============================] - 171s 351ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 6/6\n",
      "488/488 [==============================] - 170s 348ms/step - loss: 9.4333e-04 - mean_squared_error: 9.4333e-04\n",
      "Compression rate: 0.609771592276437\n",
      "Validate rocauc 0.7892107393120937\n",
      "Test rocauc 0.7914442423063844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "cr, v_rocauc, t_rocauc = get_model_stat(40000, 75)\n",
    "\n",
    "print(\"Compression rate:\", cr)\n",
    "print(\"Validate rocauc\", v_rocauc)\n",
    "print(\"Test rocauc\", t_rocauc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't build plots due to keras memory leak :'(\n",
    "\n",
    "It retains old computational graphs/data even after `clear_session` so after two-three hyperparameter sets I get out-of-memory error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "Train for 488 steps\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "488/488 [==============================] - 154s 315ms/step - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 2/6\n",
      "488/488 [==============================] - 150s 308ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 3/6\n",
      "488/488 [==============================] - 152s 311ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 4/6\n",
      "488/488 [==============================] - 151s 309ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 5/6\n",
      "488/488 [==============================] - 152s 311ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 6/6\n",
      "488/488 [==============================] - 150s 308ms/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "Train for 488 steps\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "180/488 [==========>...................] - ETA: 1:43 - loss: 0.0103 - mean_squared_error: 0.0103"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-2:\n",
      "Process Keras_worker_ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 924, in next_sample\n",
      "    return six.next(_SHARED_SEQUENCES[uid])\n",
      "  File \"<ipython-input-19-efd219723bf9>\", line 48, in generate_data\n",
      "    val = (np.float32(val) - min_arr[i]) / range_arr[i]\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "181/488 [==========>...................] - ETA: 1:42 - loss: 0.0103 - mean_squared_error: 0.0103"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d8254074e51a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmax_vocab_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m45000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmax_embedding_dim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mcr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_rocauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_rocauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_stat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_embedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mcrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mv_rocaucs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_rocauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-31e942452cd0>\u001b[0m in \u001b[0;36mget_model_stat\u001b[0;34m(max_vocab_size, max_embedding_dim, hidden_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m     model.fit(generate_data(TRAIN_PATH, train_retain, train_target, BATCH_SIZE),\n\u001b[1;32m     28\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_retain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m               epochs=6, verbose=1)\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./tmp.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "crs, v_rocaucs, t_rocaucs = [], [], []\n",
    "for max_vocab_size in [20000, 30000, 40000, 45000]:\n",
    "    for max_embedding_dim in [80, 90, 100]:\n",
    "        cr, v_rocauc, t_rocauc = get_model_stat(max_vocab_size, max_embedding_dim)\n",
    "        crs.append(cr)\n",
    "        v_rocaucs.append(v_rocauc)\n",
    "        t_rocaucs.append(t_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "s_crs, s_v_rocaucs, s_t_rocaucs = zip(*sorted(zip(crs, v_rocaucs, t_rocaucs), key=lambda x: x[0]))\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.grid(True)\n",
    "plt.plot((s_crs[0], s_crs[-1]), [0.802, 0.802], label=\"Teacher\", color=\"black\")\n",
    "plt.plot(s_crs, s_v_rocaucs, label=\"validate\")\n",
    "plt.plot(s_crs, s_t_rocaucs, label=\"test\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3519461949666341, 0.7886592033155893, 0.7910202554342162)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr, v_rocauc, t_rocauc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Наша основная задача получить модель, которая \n",
    "* в терминах ROC AUC не намного хуже модели учителя, и в то же время \n",
    "* сильно меньше по размеру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC\n",
    "\n",
    "Сравним ROC AUC модели ученика с показателем для учителя.\n",
    "\n",
    "ROC AUC учителя: 0.802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression rate\n",
    "\n",
    "Пусть \n",
    "* $a$ - \\# of the parameters in the original model $M$\n",
    "* $a^{*}$ - \\# of the parameters in compressed model $M^{*}$\n",
    "\n",
    "тогда compression rate is $$\\alpha(M,M^{*}) = \\frac{a}{a^{*}}$$\n",
    "\n",
    "Можно также посчитать comression rate просто как отношение фактических размеров моделей.\n",
    "\n",
    "Размер модели учителя - 168MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
