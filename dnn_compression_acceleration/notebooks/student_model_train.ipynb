{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Student-Model\" data-toc-modified-id=\"Student-Model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Student Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-processing\" data-toc-modified-id=\"Data-processing-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Data processing</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-Model\" data-toc-modified-id=\"Define-Model-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Define Model</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Train</a></span></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#ROC-AUC\" data-toc-modified-id=\"ROC-AUC-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>ROC AUC</a></span></li><li><span><a href=\"#Compression-rate\" data-toc-modified-id=\"Compression-rate-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Compression rate</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Model\n",
    "\n",
    "\n",
    "Нужно обучть небольшую модель на [soft таргетах](https://drive.google.com/file/d/1tBbPOUT-Ow9f3zTDApykGXYwt-KslYle/view?usp=sharing)  модели учителя, которая не сильно уступала бы в качестве учителю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from deepctr.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr.models.dcn import DCN\n",
    "\n",
    "from collections import defaultdict\n",
    "from keras.callbacks.callbacks import *\n",
    "from keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './criteo'\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train.csv')\n",
    "RETAIN_PATH = 'soft_targets_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_target = pd.read_csv(RETAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.532062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.483268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.126496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>0.750299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>0.784883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>0.010671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>117</td>\n",
       "      <td>0.466868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>121</td>\n",
       "      <td>0.554683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>135</td>\n",
       "      <td>0.110773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>139</td>\n",
       "      <td>0.262256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id      prob\n",
       "0   12  0.532062\n",
       "1   26  0.483268\n",
       "2   39  0.126496\n",
       "3   41  0.750299\n",
       "4   85  0.784883\n",
       "5  108  0.010671\n",
       "6  117  0.466868\n",
       "7  121  0.554683\n",
       "8  135  0.110773\n",
       "9  139  0.262256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_c0,_c1,_c2,_c3,_c4,_c5,_c6,_c7,_c8,_c9,_c10,_c11,_c12,_c13,_c14,_c15,_c16,_c17,_c18,_c19,_c20,_c21,_c22,_c23,_c24,_c25,_c26,_c27,_c28,_c29,_c30,_c31,_c32,_c33,_c34,_c35,_c36,_c37,_c38,_c39,id\n",
      "\n",
      "1,0,-1,\"\",\"\",1465,0,17,0,4,0,4,\"\",\"\",241546e0,38a947a1,fa673455,6a14f9b9,25c83c98,fe6b92e5,1c86e0eb,1f89b562,a73ee510,e7ba2569,755e4a50,208d9687,5978055e,07d13a8f,5182f694,f8b34416,e5ba7672,e5f8f18f,\"\",\"\",f3ddd519,\"\",32c7478e,b34f3128,\"\",\"\",12\n",
      "\n",
      "1,0,1,20,16,1548,93,42,32,912,0,15,1,16,8cf07265,942f9a8d,a8e40bcf,0365276a,25c83c98,7e0ccccf,3f4ec687,1f89b562,a73ee510,726f00fd,c4adf918,27c604a6,85dbe138,07d13a8f,a8e962af,c449f783,27c07bd6,1f868fdd,21ddcdc9,a458ea53,7eee76d1,\"\",32c7478e,9af06ad9,9d93af03,cdfe5ab7,26\n",
      "\n",
      "0,8,0,15,20,115,24,8,23,24,2,2,\"\",20,5a9ed9b0,c66fca21,78171040,373c404a,25c83c98,\"\",8ff6f5af,0b153874,a73ee510,5ba575e7,b5a9f90e,6766a7f0,949ea585,1adce6ef,8736735c,59974c9c,8efede7f,1304f63b,21ddcdc9,b1252a9d,07b2853e,\"\",32c7478e,94bde4f2,010f6491,09b76f8d,39\n",
      "\n",
      "1,88,319,\"\",4,5,4,89,40,88,3,4,12,4,05db9164,08d6d899,333440d5,fc86bde0,25c83c98,fbad5c96,f00bddf8,0b153874,a73ee510,83ff688a,55795b33,1b0c8aa3,39795005,b28479f6,bffbd637,4a838997,8efede7f,bbf70d82,\"\",\"\",16e2e3b3,\"\",32c7478e,d859b4dd,\"\",\"\",41\n",
      "\n",
      "0,0,53,\"\",10,6550,98,34,11,349,0,9,\"\",10,05db9164,207b2d81,8bd78c57,394ee067,25c83c98,6f6d9be8,283d5555,0b153874,a73ee510,3b08e48b,3d5fb018,e5f6b330,94172618,07d13a8f,0bf0feff,402a9036,e5ba7672,fa0643ee,21ddcdc9,b1252a9d,0094bc78,\"\",32c7478e,29ece3ed,001f3601,402185f3,85\n",
      "\n",
      "0,\"\",5,30,4,\"\",\"\",0,5,4,\"\",0,\"\",5,68fd1e64,207b2d81,74e1a23a,9a6888fb,25c83c98,7e0ccccf,d356c7e6,5b392875,7cc72ec2,3b08e48b,727af3e2,fb8fab62,49fe3d4e,b28479f6,231f3923,c6b1e1b2,2005abd1,25935396,21ddcdc9,5840adea,99c09e97,\"\",be7c41b4,335a6a1e,001f3601,8d8eb391,108\n",
      "\n",
      "1,\"\",-1,\"\",\"\",446,30,2,27,28,\"\",1,\"\",\"\",05db9164,38d50e09,c86b2d8d,657dc3b9,25c83c98,6f6d9be8,fe4dce68,0b153874,a73ee510,16a81a6c,68357db6,1ca7a526,768f6658,07d13a8f,e2275836,ba46c3a1,07c540c4,fffe2a63,21ddcdc9,b1252a9d,eb0fc6f8,\"\",32c7478e,df487a73,001f3601,c27f155b,117\n",
      "\n",
      "1,1,0,31,9,226,22,32,13,177,1,7,0,11,5a9ed9b0,942f9a8d,013bceb0,136ff514,25c83c98,6f6d9be8,3f4ec687,7b6fecd5,a73ee510,726f00fd,c4adf918,65b6ef3b,85dbe138,1adce6ef,ae97ecc3,a55f20ce,3486227d,1f868fdd,cd11c728,a458ea53,00680113,\"\",32c7478e,ad4c56a0,e8b83407,8270b5de,121\n",
      "\n",
      "0,\"\",0,17,3,19811,\"\",0,3,54,\"\",0,\"\",3,05db9164,f0cf0024,6f67f7e5,41274cd7,25c83c98,fbad5c96,9b6a4cc9,0b153874,a73ee510,a5aa06c8,8e3de34d,623049e6,b50e2ed0,b28479f6,e6c5b5cd,c92f3b61,1e88c74f,b04e4670,21ddcdc9,5840adea,60f6221e,\"\",32c7478e,43f13e8b,ea9a246c,731c3655,135\n",
      "\n",
      "3664931\n"
     ]
    }
   ],
   "source": [
    "max_k = 0\n",
    "with open(TRAIN_PATH) as f:\n",
    "    for k, line in enumerate(f):\n",
    "        if k < 10:\n",
    "            print(line)\n",
    "        max_k = k\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "Данные на Train/Validation/Test нужно разбить как 80/10/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_features_indices = [i for i in range(1, 14)]\n",
    "sparse_features_indices = [i for i in range(14, 40)]\n",
    "\n",
    "dense_features = ['c{}'.format(i) for i in dense_features_indices]\n",
    "sparse_features = ['c{}'.format(i) for i in sparse_features_indices]\n",
    "\n",
    "len(dense_features_indices), len(sparse_features_indices)\n",
    "\n",
    "min_arr = [0] * 40\n",
    "max_arr = [0] * 40\n",
    "range_arr = [0] * 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_minmax(filename, retain):\n",
    "    with open(filename) as f:\n",
    "        for k, line in enumerate(f):\n",
    "            if k == 0:\n",
    "                continue\n",
    "            features = line.split('\\n')[0].split(',')\n",
    "            if int(features[-1]) not in retain:\n",
    "                continue\n",
    "            for i, f_name in zip(dense_features_indices, dense_features):\n",
    "                val = features[i] if features[i] != '\"\"' else 0\n",
    "                val = float(val)\n",
    "                min_arr[i] = min(min_arr[i], val)\n",
    "                max_arr[i] = max(max_arr[i], val)\n",
    "                range_arr[i] = max_arr[i] - min_arr[i]\n",
    "\n",
    "\n",
    "def prepare_data_dict(batch):\n",
    "    data_dict = {}\n",
    "    for f_name in dense_features:\n",
    "        data_dict[f_name] = pd.core.series.Series(batch[f_name])\n",
    "\n",
    "    for f_name in sparse_features:\n",
    "        data_dict[f_name] = pd.core.series.Series(batch[f_name])\n",
    "\n",
    "    return data_dict\n",
    "                \n",
    "\n",
    "def generate_data(filename, retain, targets, batch_size=128):\n",
    "    data_teacher = defaultdict(list)\n",
    "    target = defaultdict(list)\n",
    "    labels = []\n",
    "    m = 0\n",
    "    \n",
    "    while True:\n",
    "        with open(filename) as f:\n",
    "            for k, line in enumerate(f):\n",
    "                if k == 0:\n",
    "                    continue\n",
    "                features = line.split('\\n')[0].split(',')\n",
    "                if int(features[-1]) not in retain:\n",
    "                    continue\n",
    "\n",
    "                labels.append(np.int32(features[0]))\n",
    "                target[\"target\"].append(np.float32(targets[m % len(targets)]))\n",
    "\n",
    "                for i, f_name in zip(dense_features_indices, dense_features):\n",
    "                    val = features[i] if features[i] != '\"\"' else 0\n",
    "                    val = (np.float32(val) - min_arr[i]) / range_arr[i] \n",
    "                    data_teacher[f_name].append(val)\n",
    "\n",
    "                for i, f_name in zip(sparse_features_indices, sparse_features):\n",
    "                    val = features[i] if features[i] != '\"\"' else '-1'\n",
    "                    data_teacher[f_name].append(val)\n",
    "\n",
    "                m += 1\n",
    "\n",
    "                if m % batch_size == 0:            \n",
    "                    data_dict = prepare_data_dict(data_teacher)\n",
    "                    yield data_dict, pd.core.series.Series(target[\"target\"])\n",
    "\n",
    "                    data_teacher = defaultdict(list)\n",
    "                    target = defaultdict(list)\n",
    "                    labels = []\n",
    "    \n",
    "    \n",
    "def get_data(filename, retain, targets):\n",
    "    data_teacher = defaultdict(list)\n",
    "    target = []\n",
    "    labels = []\n",
    "    \n",
    "    m = 0\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        for k, line in enumerate(f):\n",
    "            if k == 0:\n",
    "                continue\n",
    "            features = line.split('\\n')[0].split(',')\n",
    "            if int(features[-1]) not in retain:\n",
    "                continue\n",
    "\n",
    "            labels.append(np.int32(features[0]))\n",
    "            target.append(np.float32(targets[m]))\n",
    "\n",
    "            for i, f_name in zip(dense_features_indices, dense_features):\n",
    "                val = features[i] if features[i] != '\"\"' else 0\n",
    "                val = (float(val) - min_arr[i]) / range_arr[i] \n",
    "                data_teacher[f_name].append(val)\n",
    "\n",
    "            for i, f_name in zip(sparse_features_indices, sparse_features):\n",
    "                val = features[i] if features[i] != '\"\"' else '-1'\n",
    "                data_teacher[f_name].append(val)\n",
    "            \n",
    "            m += 1\n",
    "    data_dict = prepare_data_dict(data_teacher)\n",
    "    return labels, np.array(target), data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(soft_target, shuffle=False, test_size=0.2)\n",
    "test, validate = train_test_split(test, shuffle=False, test_size=0.5)\n",
    "\n",
    "all_retain = set(soft_target['id'].to_list())\n",
    "train_retain, train_target = set(train['id'].to_list()), train['prob'].to_numpy()\n",
    "test_retain, test_target = set(test['id'].to_list()), test['prob'].to_numpy()\n",
    "validate_retain, validate_target = set(validate['id'].to_list()), validate['prob'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_minmax(TRAIN_PATH, all_retain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_labels, validate_target, validate_data = get_data(TRAIN_PATH, validate_retain, validate_target)\n",
    "test_labels, test_target, test_data = get_data(TRAIN_PATH, test_retain, test_target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Можно также использовать Pruning и/или Quantinization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features_dims = dict([\n",
    "    ('c14', 1445),\n",
    "    ('c15', 556),\n",
    "    ('c16', 1130758),\n",
    "    ('c17', 360209),\n",
    "    ('c18', 304),\n",
    "    ('c19', 21),\n",
    "    ('c20', 11845),\n",
    "    ('c21', 631),\n",
    "    ('c22', 3),\n",
    "    ('c23', 49223),\n",
    "    ('c24', 5194),\n",
    "    ('c25', 985420),\n",
    "    ('c26', 3157),\n",
    "    ('c27', 26),\n",
    "    ('c28', 11588),\n",
    "    ('c29', 715441),\n",
    "    ('c30', 10),\n",
    "    ('c31', 4681),\n",
    "    ('c32', 2029),\n",
    "    ('c33', 4),\n",
    "    ('c34', 870796),\n",
    "    ('c35', 17),\n",
    "    ('c36', 15),\n",
    "    ('c37', 87605),\n",
    "    ('c38', 84),\n",
    "    ('c39', 58187)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_stat(max_vocab_size=20000, max_embedding_dim=75, hidden_size=(128, 128)):\n",
    "    fixlen_feature_columns = [SparseFeat(feat, \n",
    "                                         vocabulary_size=min(vocab_size, max_vocab_size), \n",
    "                                         embedding_dim=min(int(6 * (vocab_size) ** (0.25)), max_embedding_dim), \n",
    "                                         use_hash=True, dtype='string')\n",
    "                              for feat, vocab_size in sparse_features_dims.items()] + \\\n",
    "                            [DenseFeat(feat, 1,) for feat in dense_features]\n",
    "\n",
    "\n",
    "    linear_feature_columns = fixlen_feature_columns\n",
    "    dnn_feature_columns = fixlen_feature_columns\n",
    "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns, )\n",
    "    \n",
    "    model = DCN(linear_feature_columns, dnn_feature_columns, cross_num=2,\n",
    "            dnn_hidden_units=hidden_size, l2_reg_linear=0, l2_reg_embedding=0,\n",
    "            l2_reg_cross=0, l2_reg_dnn=0, init_std=0.0001, seed=1024, \n",
    "            dnn_use_bn=True, dnn_activation='relu', task='binary')\n",
    "\n",
    "    model.compile(\"adam\", 'mean_squared_error',\n",
    "                  metrics=['mean_squared_error'], )\n",
    "    \n",
    "    BATCH_SIZE = 3000\n",
    "    EPOCHS = 6\n",
    "    \n",
    "    model.fit(generate_data(TRAIN_PATH, train_retain, train_target, BATCH_SIZE),\n",
    "              use_multiprocessing=True, steps_per_epoch=3*len(train_retain)//(BATCH_SIZE * EPOCHS), \n",
    "              epochs=6, verbose=1)\n",
    "    model.save_weights('./tmp.h5')\n",
    "    \n",
    "    compression_rate = (1024 * 1024 * 168)/os.path.getsize('tmp.h5')\n",
    "    \n",
    "    pred_proba = model.predict(validate_data)\n",
    "    validation_rocauc = roc_auc_score(validate_labels, pred_proba)\n",
    "    pred_proba = model.predict(test_data)\n",
    "    test_rocauc = roc_auc_score(test_labels, pred_proba)\n",
    "    \n",
    "    clear_session()\n",
    "    \n",
    "    return compression_rate, validation_rocauc, test_rocauc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "Train for 488 steps\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "488/488 [==============================] - 169s 346ms/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 2/6\n",
      "488/488 [==============================] - 166s 341ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 3/6\n",
      "488/488 [==============================] - 168s 343ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 4/6\n",
      "488/488 [==============================] - 166s 341ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 5/6\n",
      "488/488 [==============================] - 169s 346ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 6/6\n",
      "488/488 [==============================] - 167s 342ms/step - loss: 9.6464e-04 - mean_squared_error: 9.6464e-04\n",
      "\n",
      "\n",
      "\n",
      "Compression rate: 1.639958326472275\n",
      "Validate rocauc 0.7888861936680214\n",
      "Test rocauc 0.7911934366991362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "cr, v_rocauc, t_rocauc = get_model_stat(40000, 75)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Compression rate:\", cr)\n",
    "print(\"Validate rocauc\", v_rocauc)\n",
    "print(\"Test rocauc\", t_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "Train for 488 steps\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "488/488 [==============================] - 141s 290ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 2/6\n",
      "488/488 [==============================] - 137s 280ms/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 3/6\n",
      "488/488 [==============================] - 138s 282ms/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 4/6\n",
      "488/488 [==============================] - 137s 280ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 5/6\n",
      "488/488 [==============================] - 138s 282ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 6/6\n",
      "488/488 [==============================] - 136s 279ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "\n",
      "\n",
      "\n",
      "Compression rate: 5.24401682793377\n",
      "Validate rocauc 0.787183258301624\n",
      "Test rocauc 0.7894640907015611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/argentumwalker/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "cr, v_rocauc, t_rocauc = get_model_stat(10000, 75)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Compression rate:\", cr)\n",
    "print(\"Validate rocauc\", v_rocauc)\n",
    "print(\"Test rocauc\", t_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "Train for 488 steps\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "488/488 [==============================] - 124s 255ms/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 2/6\n",
      "488/488 [==============================] - 121s 249ms/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 3/6\n",
      "488/488 [==============================] - 123s 253ms/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 4/6\n",
      "488/488 [==============================] - 123s 251ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 5/6\n",
      "488/488 [==============================] - 125s 256ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 6/6\n",
      "488/488 [==============================] - 122s 251ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "\n",
      "\n",
      "\n",
      "Compression rate: 13.64507589653087\n",
      "Validate rocauc 0.7879183896715284\n",
      "Test rocauc 0.7904537542318204\n"
     ]
    }
   ],
   "source": [
    "cr, v_rocauc, t_rocauc = get_model_stat(10000, 25)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Compression rate:\", cr)\n",
    "print(\"Validate rocauc\", v_rocauc)\n",
    "print(\"Test rocauc\", t_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 122 48 57\n"
     ]
    }
   ],
   "source": [
    "print(ord('a'), ord('z'), ord('0'), ord('9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "Train for 488 steps\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "488/488 [==============================] - 125s 256ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 2/6\n",
      "488/488 [==============================] - 121s 247ms/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 3/6\n",
      "488/488 [==============================] - 122s 251ms/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 4/6\n",
      "488/488 [==============================] - 120s 246ms/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 5/6\n",
      "488/488 [==============================] - 122s 250ms/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 6/6\n",
      "488/488 [==============================] - 121s 247ms/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "\n",
      "\n",
      "\n",
      "Compression rate: 45.686457821126474\n",
      "Validate rocauc 0.784907492798154\n",
      "Test rocauc 0.7873023644509987\n"
     ]
    }
   ],
   "source": [
    "cr, v_rocauc, t_rocauc = get_model_stat(2000, 25)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Compression rate:\", cr)\n",
    "print(\"Validate rocauc\", v_rocauc)\n",
    "print(\"Test rocauc\", t_rocauc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets try something new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple one-hot encoding\n",
    "char_encodings = dict([(key, value) for value, key in enumerate(list(range(97, 123)) + list(range(48, 58)))])\n",
    "eye = torch.eye(len(char_encodings)).cuda()\n",
    "zero_word = torch.zeros((8, 36)).cuda()\n",
    "\n",
    "def encode_word(w):\n",
    "    result = []\n",
    "    for c in w:\n",
    "        result.append(eye[char_encodings[ord(c)]].unsqueeze(0))\n",
    "    return torch.cat(result, dim=0)\n",
    "\n",
    "def encode_object(features):\n",
    "    dense = []\n",
    "    for i in dense_features_indices:\n",
    "        val = features[i] if features[i] != '\"\"' else 0\n",
    "        val = (np.float32(val) - min_arr[i]) / range_arr[i] \n",
    "        dense.append(val)\n",
    "    dense = torch.Tensor(dense).unsqueeze(0).cuda()\n",
    "    \n",
    "    result = [dense]\n",
    "    for i in sparse_features_indices:\n",
    "        result.append(encode_word(features[i]).unsqueeze(0) if features[i] != '\"\"' else zero_word.unsqueeze(0))\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "def encode_batch(batch_features, batch_targets):\n",
    "    target = torch.Tensor(batch_targets).unsqueeze(-1).cuda()\n",
    "    feature_encodings = [torch.cat(b, dim=0) for b in zip(*[encode_object(f) for f in batch_features])]\n",
    "    return feature_encodings, target\n",
    "\n",
    "\n",
    "def load_full_data(filename, retain, targets):\n",
    "    batch = []\n",
    "    labels = []\n",
    "    target = []\n",
    "    m = 0\n",
    "\n",
    "    with open(filename) as f:\n",
    "        for k, line in enumerate(f):\n",
    "            if k == 0:\n",
    "                continue\n",
    "            features = line.split('\\n')[0].split(',')\n",
    "            if int(features[-1]) not in retain:\n",
    "                continue\n",
    "\n",
    "            labels.append(np.int32(features[0]))\n",
    "            batch.append(features[1:len(features)])\n",
    "            target.append(np.float32(targets[m % len(targets)]))\n",
    "            m += 1\n",
    "    batch, target = encode_batch(batch, target)\n",
    "    yield batch, target, labels\n",
    "\n",
    "\n",
    "def load_batch_data(filename, retain, targets, batch_size=128):\n",
    "    batch = []\n",
    "    labels = []\n",
    "    target = []\n",
    "    m = 0\n",
    "    \n",
    "    while True:\n",
    "        with open(filename) as f:\n",
    "            for k, line in enumerate(f):\n",
    "                if k == 0:\n",
    "                    continue\n",
    "                features = line.split('\\n')[0].split(',')\n",
    "                if int(features[-1]) not in retain:\n",
    "                    continue\n",
    "                \n",
    "                labels.append(np.int32(features[0]))\n",
    "                batch.append(features)\n",
    "                target.append(np.float32(targets[m % len(targets)]))\n",
    "                m += 1\n",
    "\n",
    "                if m % batch_size == 0:\n",
    "                    yield encode_batch(batch, target)\n",
    "\n",
    "                    batch = []\n",
    "                    target = []\n",
    "                    labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, emb_size, word_len=8, chars=36):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(chars, emb_size)\n",
    "        self.emb = nn.Linear(chars, emb_size)\n",
    "        self.attention_rnn = nn.LSTM(emb_size, emb_size, batch_first=True)\n",
    "        self.emb_size = emb_size\n",
    "        self.word_len = word_len\n",
    "    \n",
    "    def forward(self, x):\n",
    "        key = self.key(x)\n",
    "        emb = self.emb(x)\n",
    "        attention, _ = self.attention_rnn(key)\n",
    "        attention = F.softmax(attention, dim=-2)\n",
    "        return (attention * emb).sum(dim=-2)\n",
    "    \n",
    "class MimicModel(nn.Module):\n",
    "    def __init__(self, emb_size=100):\n",
    "        super().__init__()\n",
    "        self.word_encoders = nn.ModuleList([Embedding(emb_size) for _ in range(len(sparse_features))])\n",
    "        self.output = nn.Sequential(\n",
    "            torch.nn.Linear(emb_size * len(sparse_features) + len(dense_features), 128),\n",
    "            torch.nn.ELU(),\n",
    "            torch.nn.Linear(128, 128),\n",
    "            torch.nn.ELU(),\n",
    "            torch.nn.Linear(128, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        dense = xs[0]\n",
    "        words = [e(w) for w, e in zip(xs[1:], self.word_encoders)]\n",
    "        x = torch.cat([dense] + words, dim=-1)\n",
    "        return self.output(x)\n",
    "    \n",
    "    def predict_proba(self, xs):\n",
    "        with torch.no_grad():\n",
    "            proba = self.forward(xs)\n",
    "        return proba.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ed4ac960d54492a3455da5a003a320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1431), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | 0.13187697529792786\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "model = MimicModel()\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "generator = load_batch_data(TRAIN_PATH, train_retain, train_target, BATCH_SIZE)\n",
    "for i in tqdm(range(len(train_retain) // BATCH_SIZE)):\n",
    "    batch, target = next(generator)\n",
    "    pred = model(batch)\n",
    "    loss = F.mse_loss(target, pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 20 == 0:\n",
    "        print(i, \"|\", loss.detach().item())    \n",
    "\n",
    "print(\"Final loss:\", loss.detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Наша основная задача получить модель, которая \n",
    "* в терминах ROC AUC не намного хуже модели учителя, и в то же время \n",
    "* сильно меньше по размеру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC\n",
    "\n",
    "Сравним ROC AUC модели ученика с показателем для учителя.\n",
    "\n",
    "ROC AUC учителя: 0.802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression rate\n",
    "\n",
    "Пусть \n",
    "* $a$ - \\# of the parameters in the original model $M$\n",
    "* $a^{*}$ - \\# of the parameters in compressed model $M^{*}$\n",
    "\n",
    "тогда compression rate is $$\\alpha(M,M^{*}) = \\frac{a}{a^{*}}$$\n",
    "\n",
    "Можно также посчитать comression rate просто как отношение фактических размеров моделей.\n",
    "\n",
    "Размер модели учителя - 168MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
