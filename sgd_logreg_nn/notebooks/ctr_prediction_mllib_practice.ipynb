{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CTR-prediction\" data-toc-modified-id=\"CTR-prediction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>CTR-prediction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Problem-Formulation\" data-toc-modified-id=\"Problem-Formulation-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Problem Formulation</a></span></li><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dataset-construction:\" data-toc-modified-id=\"Dataset-construction:-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Dataset construction:</a></span></li><li><span><a href=\"#Format:\" data-toc-modified-id=\"Format:-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Format:</a></span></li></ul></li><li><span><a href=\"#Metrics\" data-toc-modified-id=\"Metrics-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Metrics</a></span></li></ul></li><li><span><a href=\"#Dataset-preprocessing\" data-toc-modified-id=\"Dataset-preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataset preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#ML-Pipelines-(Transformers,-Estimators)\" data-toc-modified-id=\"ML-Pipelines-(Transformers,-Estimators)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/latest/ml-pipeline.html#pipeline-components\" target=\"_blank\">ML Pipelines (Transformers, Estimators)</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-stages-of-pipeline\" data-toc-modified-id=\"Prepare-stages-of-pipeline-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Prepare stages of pipeline</a></span></li><li><span><a href=\"#Fit-and-save-pipeline\" data-toc-modified-id=\"Fit-and-save-pipeline-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Fit and save pipeline</a></span></li><li><span><a href=\"#Load-fitted-pipeline\" data-toc-modified-id=\"Load-fitted-pipeline-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Load fitted pipeline</a></span></li><li><span><a href=\"#Transform-dataset-using-pipeline\" data-toc-modified-id=\"Transform-dataset-using-pipeline-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Transform dataset using pipeline</a></span></li><li><span><a href=\"#Make-dataset-split\" data-toc-modified-id=\"Make-dataset-split-2.1.5\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Make dataset split</a></span></li></ul></li></ul></li><li><span><a href=\"#Classification\" data-toc-modified-id=\"Classification-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html\" target=\"_blank\">Classification</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression\" target=\"_blank\">Logistic Regression</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-and-Train-model\" data-toc-modified-id=\"Define-and-Train-model-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Define and Train model</a></span></li></ul></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html\" target=\"_blank\">Evaluation</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Binary-classification-metrics\" data-toc-modified-id=\"Binary-classification-metrics-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html#binary-classification\" target=\"_blank\">Binary classification metrics</a></a></span></li><li><span><a href=\"#Make-submission\" data-toc-modified-id=\"Make-submission-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Make submission</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTR-prediction\n",
    "\n",
    "## Problem Formulation\n",
    "\n",
    "$\\newcommand{\\vecw}{{\\bf w}}$\n",
    "$\\newcommand{\\vecx}{{\\bf x}}$\n",
    "\n",
    "* Dataset: $X^N = \\{ z_i \\}^N_{i=1}$, где $z_i = (\\vecx_i, y_i) \\sim P(z), y_i \\in \\{0,1\\}$\n",
    "* Prediction: $$ \\hat{y}_i = f_{\\vecw}(\\vecx_i) =  \\mathbb{P} \\left\\{ y = 1 \\mid \\vecx_i \\right\\} $$\n",
    "* Loss function (Binary Cross-Entropy): $$ \\min\\limits_{\\vecw} \\quad \\frac{\\lambda}{2}\\| \\vecw \\|^2_2 - \\frac{1}{N} \\sum\\limits_{i=1}^{N} y_i \\log \\hat{y}_i + (1-y_i) \\log(1-\\hat{y}_i) $$\n",
    "\n",
    "## Dataset\n",
    "$ $\n",
    "<details>\n",
    "  <summary>Click here to see the details</summary>\n",
    "\n",
    "For more details see `/data/criteo/readme.txt`\n",
    "\n",
    "### Dataset construction:\n",
    "\n",
    "\n",
    ">There are 13 features taking **integer** values and 26\n",
    "**categorical** features. The values of the categorical features have been hashed\n",
    "onto 32 bits for anonymization purposes. \n",
    "Some features may have missing values.\n",
    "\n",
    "> The rows are chronologically ordered by `id` column.\n",
    "\n",
    "> The test set corresponds to events on the day following the training period. \n",
    "The first column (`label`) has been removed.\n",
    "\n",
    "\n",
    "### Format:\n",
    "\n",
    "> The columns are comma separeted with the following schema:\n",
    "`<label>,<integer feature 1>, ... <integer feature 13>,<categorical feature 1>, ... <categorical feature 26>,<id>`\n",
    "\n",
    "> When a value is missing, the field is \"\". There is no `label` field in the test set.\n",
    "\n",
    "</details>\n",
    "    \n",
    "## Metrics\n",
    "\n",
    "The evaluation metrics for this task are\n",
    "* ROC AUC\n",
    "* LogLoss\n",
    "* [Normalized Entropy](https://quinonero.net/Publications/predicting-clicks-facebook.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"spark_sql_examples\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.cores\", \"5\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = '/workspace/data/criteo'\n",
    "DATA_PATH = '/workspace'\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train.csv')\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'test.csv')\n",
    "SUBMIT_PATH = os.path.join(DATA_PATH, 'submission.csv')\n",
    "\n",
    "PREPROCESSING_PIPELINE_PATH = os.path.join(DATA_PATH, 'preprocessing_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/MLBD/sgd_logreg_nn/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets begin our introduction to Spark [MLlib](https://spark.apache.org/docs/latest/ml-guide.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Dataset preprocessing\n",
    "\n",
    "Before we can train any prediction model on our dataset we need to conver each row into real-valued features vector ($\\vecx \\in \\mathbb{R}^n$).\n",
    "\n",
    "Spark MLlib provides easy to use tools for preprocessing raw features and turning them into suitable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(False, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: integer (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: integer (nullable = true)\n",
      " |-- _c7: integer (nullable = true)\n",
      " |-- _c8: integer (nullable = true)\n",
      " |-- _c9: integer (nullable = true)\n",
      " |-- _c10: integer (nullable = true)\n",
      " |-- _c11: integer (nullable = true)\n",
      " |-- _c12: integer (nullable = true)\n",
      " |-- _c13: integer (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      " |-- _c21: string (nullable = true)\n",
      " |-- _c22: string (nullable = true)\n",
      " |-- _c23: string (nullable = true)\n",
      " |-- _c24: string (nullable = true)\n",
      " |-- _c25: string (nullable = true)\n",
      " |-- _c26: string (nullable = true)\n",
      " |-- _c27: string (nullable = true)\n",
      " |-- _c28: string (nullable = true)\n",
      " |-- _c29: string (nullable = true)\n",
      " |-- _c30: string (nullable = true)\n",
      " |-- _c31: string (nullable = true)\n",
      " |-- _c32: string (nullable = true)\n",
      " |-- _c33: string (nullable = true)\n",
      " |-- _c34: string (nullable = true)\n",
      " |-- _c35: string (nullable = true)\n",
      " |-- _c36: string (nullable = true)\n",
      " |-- _c37: string (nullable = true)\n",
      " |-- _c38: string (nullable = true)\n",
      " |-- _c39: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only first two categorical features for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_columns = ['_c{}'.format(i) for i in range(1, 14)]\n",
    "cat_columns = ['_c{}'.format(i) for i in range(14, 40)][:2]\n",
    "len(num_columns), len(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0, subset=num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ML Pipelines (Transformers, Estimators)](https://spark.apache.org/docs/latest/ml-pipeline.html#pipeline-components)\n",
    "\n",
    "\n",
    "MLlib standardizes APIs for machine learning algorithms to make it easier to combine multiple algorithms into a single pipeline, or workflow.\n",
    "\n",
    "* `Transformer`: A Transformer is an algorithm which can transform one DataFrame into another DataFrame. E.g., an ML model is a Transformer which transforms a DataFrame with features into a DataFrame with predictions.\n",
    "\n",
    "\n",
    "* `Estimator`: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.\n",
    "\n",
    "\n",
    "* `Pipeline`: A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.\n",
    "\n",
    "---\n",
    "Basically speaking `transformer` is an instance of class that implements `transform` method, and both `estimator` and `pipeline` implements `transform` and `fit` methods.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare stages of pipeline\n",
    "\n",
    "We might benefit from using `StringIndexer, OneHotEncoderEstimator, VectorAssembler` (see [doc](https://spark.apache.org/docs/latest/ml-features) for details) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_columns = list(map((lambda col: col + '_index'), cat_columns))\n",
    "vector_columns = list(map((lambda col: col + '_vector'), cat_columns))\n",
    "\n",
    "stages = [StringIndexer(inputCol=col, outputCol=ind_col, handleInvalid='keep') \n",
    "                   for col, ind_col in zip(cat_columns, index_columns)]\n",
    "\n",
    "stages.append(OneHotEncoderEstimator(inputCols=index_columns, outputCols=vector_columns))\n",
    "stages.append(VectorAssembler(inputCols=num_columns + vector_columns, outputCol='features'))\n",
    "\n",
    "preprocessing_pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and save pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline_model = preprocessing_pipeline.fit(df)\n",
    "preprocessing_pipeline_model.write().overwrite().save(PREPROCESSING_PIPELINE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fitted pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline_model = PipelineModel.load(PREPROCESSING_PIPELINE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dataset using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing_pipeline_model.transform(df)\n",
    "df = df.select('id', 'features', F.col('_c0').alias('label')).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset split\n",
    "\n",
    "Spark provides [randomSplit](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.randomSplit) method.\n",
    "\n",
    "It is not the best choice in our task since we have chronological order in data.\n",
    "\n",
    "We need to implement our own split function which will split the data in parts with respect to chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_col(df, split_col, parts_fractions):\n",
    "    \"\"\"\n",
    "    df - DataFrame\n",
    "    split_col - total order column\n",
    "    parts_fractions - fractions of resulting parts\n",
    "    \"\"\"\n",
    "    sums = [[0, 0]]\n",
    "    for pf in parts_fractions:\n",
    "        sums.append((sums[-1][1], sums[-1][1] + pf))\n",
    "        \n",
    "    split_window = Window().orderBy(split_col)\n",
    "    df = df.withColumn('fraction', F.percent_rank().over(split_window))\n",
    "    \n",
    "    return [df.filter(low < df['fraction']).filter(high >= df['fraction']).drop('fraction') for low, high in sums[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_by_col(df, 'id', [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7999992359759289, 0.09999983628055618, 0.10000038201203557)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count() / N, val_df.count() / N, test_df.count() / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# [Classification](https://spark.apache.org/docs/latest/ml-classification-regression.html)\n",
    "\n",
    "## [Logistic Regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression)\n",
    "\n",
    "### Define and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=100, regParam=0.01, elasticNetParam=0.1)\n",
    "lr_model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id=455266578481, features=SparseVector(1944, {3: 3.0, 4: 20288.0, 5: 14.0, 6: 1.0, 7: 3.0, 8: 11.0, 10: 1.0, 12: 3.0, 13: 1.0, 1494: 1.0}), label=0, rawPrediction=DenseVector([1.3868, -1.3868]), probability=DenseVector([0.8001, 0.1999]), prediction=0.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.transform(val_df).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# [Evaluation](https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html)\n",
    "\n",
    "## [Binary classification metrics](https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html#binary-classification)\n",
    "\n",
    "* ROC AUC\n",
    "* LogLoss\n",
    "* Normalized Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc(model, df):\n",
    "    predictions = lr_model.transform(df).rdd.map(lambda row: (float(row['probability'][1]), float(row['label'])))\n",
    "    return BinaryClassificationMetrics(predictions).areaUnderROC\n",
    "\n",
    "def logloss(model, df):\n",
    "    predictions = lr_model.transform(df).rdd.map(lambda row: (float(row['probability'][1]), float(row['label'])))\n",
    "    return predictions.map(lambda row: -row[1] * np.log(row[0]) - (1. - row[1]) * np.log(1. - row[0])).mean()\n",
    "\n",
    "def ne(model, df):\n",
    "    label_mean = df.rdd.map(lambda row: float(row['label'])).mean()\n",
    "    ll = -label_mean * np.log(label_mean) - (1. - label_mean) * np.log(1. - label_mean)\n",
    "    return logloss(model, df) / ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7026663778468325"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocauc(lr_model, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9203179953421851"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne(lr_model, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7032453900744162"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocauc(lr_model, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9196657658665146"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne(lr_model, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission\n",
    "\n",
    "Join the [competition](https://www.kaggle.com/c/mlbd-20-ctr-prediction-1) and make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = split_by_col(df, 'id', [0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TEST_PATH)\n",
    "\n",
    "\n",
    "df_test = df_test.fillna(0, subset=num_columns)\n",
    "df_test = preprocessing_pipeline_model.transform(df_test)\n",
    "df_test = df_test.select('id', 'features').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.7027812779655739 time: 149.21538066864014\n",
      "0.0 0.01 0.7027812779655739 time: 144.66799235343933\n",
      "0.0 0.05 0.7027812779655739 time: 148.87183690071106\n",
      "0.0 0.1 0.7027812779655739 time: 146.8454830646515\n",
      "0.0 0.2 0.7027812779655739 time: 149.15402388572693\n",
      "0.0 0.3 0.7027812779655739 time: 149.83160066604614\n",
      "0.01 0.0 0.7015180440909613 time: 141.76691102981567\n",
      "0.01 0.01 0.7020444697803493 time: 141.69171380996704\n",
      "0.01 0.05 0.7030019958711722 time: 148.0107831954956\n",
      "0.01 0.1 0.7028727523239727 time: 147.66852521896362\n",
      "0.01 0.2 0.7012065215271714 time: 173.71195220947266\n",
      "0.01 0.3 0.699128910974797 time: 169.24596738815308\n",
      "0.05 0.0 0.6997982688771679 time: 151.2134394645691\n",
      "0.05 0.01 0.7011692582181586 time: 137.39351201057434\n",
      "0.05 0.05 0.6985748385245453 time: 140.28346872329712\n",
      "0.05 0.1 0.6942933079141528 time: 141.90267515182495\n",
      "0.05 0.2 0.6877523426890874 time: 144.2478904724121\n",
      "0.05 0.3 0.6834199102624059 time: 140.88623094558716\n",
      "0.1 0.0 0.6993529450927682 time: 139.15235424041748\n",
      "0.1 0.01 0.7005247545373756 time: 146.65115976333618\n",
      "0.1 0.05 0.694172722074932 time: 147.64869713783264\n",
      "0.1 0.1 0.688308994620132 time: 142.0682671070099\n",
      "0.1 0.2 0.6795397536326498 time: 144.4125111103058\n",
      "0.1 0.3 0.6760425646587681 time: 149.66341733932495\n",
      "0.2 0.0 0.6992889940931218 time: 125.29026126861572\n",
      "0.2 0.01 0.6989261194370641 time: 135.7708842754364\n",
      "0.2 0.05 0.6887365261761089 time: 149.68350315093994\n",
      "0.2 0.1 0.6809852863111114 time: 143.91772031784058\n",
      "0.2 0.2 0.6622329901481186 time: 144.72493767738342\n",
      "0.2 0.3 0.6619371400413334 time: 143.2149736881256\n",
      "--------------------------------\n",
      "Best: (0.01, 0.05) 0.7030019958711722\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "best_params = None\n",
    "best_rocauc = 0.\n",
    "best_model = None\n",
    "\n",
    "lr = LogisticRegression(maxIter=20)\n",
    "\n",
    "for regParam in [0., 0.01, 0.05, 0.1, 0.2]: \n",
    "    for elasticNetParam in [0., 0.01, 0.05, 0.1, 0.2, 0.3]:\n",
    "        t = time.time()\n",
    "        lr.setParams(regParam=regParam, elasticNetParam=elasticNetParam)\n",
    "        lr_model = lr.fit(train_df)\n",
    "        metric = rocauc(lr_model, val_df)\n",
    "        print(regParam, elasticNetParam, metric, \"time:\", time.time() - t)\n",
    "        \n",
    "        if metric > best_rocauc:\n",
    "            best_rocauc = metric\n",
    "            best_params = (regParam, elasticNetParam)\n",
    "            best_model = lr_model\n",
    "print(\"--------------------------------\")\n",
    "print(\"Best:\", best_params, best_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_predictions = best_model.transform(df_test).select('id', 'probability').toPandas()\n",
    "df_predictions['proba'] = df_predictions['probability'].map(lambda p: p[1] if not pd.isna(p[1]) else 0.)\n",
    "df_predictions[['id', 'proba']].to_csv(SUBMIT_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
