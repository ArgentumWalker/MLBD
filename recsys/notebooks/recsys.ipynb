{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Movie-recommendation\" data-toc-modified-id=\"Movie-recommendation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Movie recommendation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Dataset</a></span></li><li><span><a href=\"#Evaluation-Protocol\" data-toc-modified-id=\"Evaluation-Protocol-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Evaluation Protocol</a></span></li><li><span><a href=\"#Models\" data-toc-modified-id=\"Models-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#ALS\" data-toc-modified-id=\"ALS-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/latest/ml-collaborative-filtering.html#explicit-vs-implicit-feedback\" target=\"_blank\">ALS</a></a></span></li><li><span><a href=\"#Ваша-формулировка\" data-toc-modified-id=\"Ваша-формулировка-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Ваша формулировка</a></span></li></ul></li><li><span><a href=\"#Evaluation-Results\" data-toc-modified-id=\"Evaluation-Results-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Evaluation Results</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie recommendation\n",
    "\n",
    "Ваша задача - рекомендация фильмов для пользователей\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"spark_sql_examples\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.cores\", \"5\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "\n",
    "`MovieLens-25M`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/workspace/data/ml-25m'\n",
    "\n",
    "RATINGS_PATH = os.path.join(DATA_PATH, 'ratings.csv')\n",
    "MOVIES_PATH = os.path.join(DATA_PATH, 'movies.csv')\n",
    "TAGS_PATH = os.path.join(DATA_PATH, 'tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "ratings_df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + RATINGS_PATH) \\\n",
    "\n",
    "movies_df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + MOVIES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Protocol\n",
    "\n",
    "Так как мы хотим оценивать качество разных алгоритмов рекомендаций, то в первую очередь нам нужно определить\n",
    "* Как разбить данные на `Train`/`Validation`/`Test`;\n",
    "* Какие метрики использовать для оценки качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "rank_window = Window().orderBy('timestamp')\n",
    "\n",
    "train_df = ratings_df \\\n",
    "    .withColumn('rank', F.percent_rank().over(rank_window)) \\\n",
    "    .filter(F.col('rank') <= 0.8) \\\n",
    "    .drop('rank').cache()\n",
    "train_users = train_df.select('userId').distinct()\n",
    "\n",
    "validate_df = ratings_df \\\n",
    "    .withColumn('rank', F.percent_rank().over(rank_window)) \\\n",
    "    .filter((F.col('rank') > 0.8) & (F.col('rank') <= 0.9)) \\\n",
    "    .drop('rank') \\\n",
    "    .join(train_users, 'userId').cache()\n",
    "    \n",
    "test_df = ratings_df \\\n",
    "    .withColumn('rank', F.percent_rank().over(rank_window)) \\\n",
    "    .filter(F.col('rank') > 0.9) \\\n",
    "    .drop('rank') \\\n",
    "    .join(train_users, 'userId').cache()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "def precision_recall_hr(predicted, df):\n",
    "    predicted = predicted \\\n",
    "        .rdd \\\n",
    "        .flatMap(lambda rec: [Row(userId = rec['userId'], movieId = row['movieId'], rank=rank) \n",
    "                              for rank, row in enumerate(rec['recommendations'])]) \\\n",
    "        .toDF()\n",
    "    \n",
    "    true = df \\\n",
    "        .join(predicted.select('userId').distinct(), 'userId') \\\n",
    "        .select('movieId', 'userId')\n",
    "    \n",
    "    predicted_sizes = predicted \\\n",
    "        .groupBy('userId') \\\n",
    "        .count().cache()\n",
    "        \n",
    "    true_sizes = true \\\n",
    "        .groupBy('userId') \\\n",
    "        .count().cache()\n",
    "    \n",
    "    intersection_sizes = predicted \\\n",
    "        .join(true, (true['movieId'] == predicted['movieId']) & (true['userId'] == predicted['userId'])) \\\n",
    "        .select(true['movieId'], true['userId']) \\\n",
    "        .groupBy('userId') \\\n",
    "        .count().cache()\n",
    "    \n",
    "    precision = predicted_sizes \\\n",
    "        .join(intersection_sizes, 'userId') \\\n",
    "        .withColumn(\"proportion\", intersection_sizes['count'] / predicted_sizes['count']) \\\n",
    "        .agg({'proportion': 'avg'}) \\\n",
    "        .collect()[0][0]\n",
    "    \n",
    "    recall = true_sizes \\\n",
    "        .join(intersection_sizes, 'userId') \\\n",
    "        .withColumn(\"proportion\", intersection_sizes['count'] / true_sizes['count']) \\\n",
    "        .agg({'proportion': 'avg'}) \\\n",
    "        .collect()[0][0]\n",
    "    \n",
    "    hr = intersection_sizes \\\n",
    "        .withColumn('bin', (F.col('count') > F.lit(0)).cast('double')) \\\n",
    "        .agg({'bin': 'avg'}) \\\n",
    "        .collect()[0][0]\n",
    "    \n",
    "    return precision, recall, hr\n",
    "\n",
    "def k_metrics(model, df, k=5):\n",
    "    return precision_recall_hr(model.recommendForAllUsers(k), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "def cosine_dist(selected_features, features):\n",
    "    return float(cosine(selected_features, features))\n",
    "\n",
    "cosine_dist_udf = F.udf(cosine_dist, FloatType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Теперь мы можем перейти к формулировке задачи в терминах машинного обучения.\n",
    "\n",
    "Одна из формулировок, к которой мы сведем нашу задачу - **Matrix Completetion**. Данную задачу будем решать с помощью `ALS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ALS](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html#explicit-vs-implicit-feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(maxIter=20, regParam=.05, userCol='userId', itemCol='movieId', ratingCol='rating', \n",
    "          coldStartStrategy='drop', rank=10, implicitPrefs=False, nonnegative=True)\n",
    "als_model = als.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите для выбранных вами фильмов топ-20 наиболее похожих фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand\n",
    "\n",
    "films = movies_df.orderBy(rand()).limit(20).cache()\n",
    "films.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def closest_als(model, target, n=20):\n",
    "    target_films_ids = target.select('movieId')\n",
    "    movie_features = model.itemFactors.withColumnRenamed('id', 'movieId')\n",
    "    window = Window().partitionBy('targetMovieId').orderBy(F.col('dist').asc())\n",
    "\n",
    "    result = target_films_ids \\\n",
    "        .join(movie_features, 'movieId') \\\n",
    "        .withColumnRenamed('movieId', 'targetMovieId') \\\n",
    "        .withColumnRenamed('features', 'targetFeatures') \\\n",
    "        .join(movie_features, F.col('movieId') != F.col('targetMovieId')) \\\n",
    "        .withColumn('dist', cosine_dist_udf('targetFeatures', 'features')) \\\n",
    "        .withColumn('rank', F.row_number().over(window)) \\\n",
    "        .filter(F.col('rank') <= n) \\\n",
    "        .select('targetMovieId', 'movieId', 'rank') \\\n",
    "        .join(movies_df, 'movieId') \\\n",
    "        .join(target.withColumnRenamed('movieId', 'targetMovieId').withColumnRenamed('title', 'targetTitle'), 'targetMovieId') \\\n",
    "        .select('targetMovieId', 'movieId', 'rank', 'title', 'targetTitle')\n",
    "    \n",
    "    return result\n",
    "\n",
    "collected_results = closest_als(als_model, films).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prev_target = -1\n",
    "for row in collected_results:\n",
    "    if prev_target != row['targetMovieId']:\n",
    "        prev_target = row['targetMovieId']\n",
    "        print(\"-\"*60)\n",
    "        print(\"-\"*60)\n",
    "        print(\"Closest to\", row[\"targetTitle\"])\n",
    "        print(\"-\"*60)\n",
    "    print(row[\"rank\"], row['title'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваша формулировка\n",
    "\n",
    "На лекции было еще несколько ML формулировок задачи рекомендаций. Выберете одну из них и реализуйте метод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Results\n",
    "\n",
    "Сравните реализованные методы с помощью выбранных метрик. Не забывайте про оптимизацию гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k_metrics(als_model, validate_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_metrics(als_model, validate_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_metrics(als_model, validate_df, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
